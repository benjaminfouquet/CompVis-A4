{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from classes.CNNModel import CNNModel\n",
    "from classes.TrainDataset import TrainDataset\n",
    "from classes.TestDataset import TestDataset\n",
    "from utils.cos_sim import cos_sim_make_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan:\n",
    "- Use a pre-trained model for feature extraction\n",
    "- Make pre-trained/homemade model for feature processing\n",
    "- Compute 20*20 asymetric cosine similarity matrix\n",
    "- Select top 2 images most similar to 'left' image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = 'data/train/'\n",
    "test_folder = 'data/test/'\n",
    "csv_folder = 'data/'\n",
    "\n",
    "train_csv = csv_folder + 'train.csv'\n",
    "train_candidates_csv = csv_folder + 'train_candidates.csv'\n",
    "test_candidates_csv = csv_folder + 'test_candidates.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNNModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((49, 40)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Define the dataset and data loader\n",
    "train_dataset = TrainDataset(train_csv, train_candidates_csv, train_folder+'left', train_folder+'all', transform=transform)\n",
    "test_dataset = TestDataset(test_candidates_csv, test_folder+'left', test_folder+'all', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make fisrt predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 200 samples in 4.18 seconds\n",
      "Processed 400 samples in 8.35 seconds\n",
      "Processed 600 samples in 12.73 seconds\n",
      "Processed 800 samples in 16.62 seconds\n",
      "Processed 1000 samples in 20.64 seconds\n",
      "Processed 1200 samples in 25.05 seconds\n",
      "Processed 1400 samples in 29.46 seconds\n",
      "Processed 1600 samples in 34.09 seconds\n",
      "Processed 1800 samples in 38.61 seconds\n",
      "Processed 2000 samples in 42.50 seconds\n"
     ]
    }
   ],
   "source": [
    "df_output = cos_sim_make_output(test_loader, test_candidates_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clip ResNet 50x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install --yes -c pytorch pytorch=1.7.1 torchvision cudatoolkit=11.0\n",
    "# !pip install ftfy regex tqdm\n",
    "# !pip install git+https://github.com/openai/CLIP.git\n",
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "# New weights with accuracy 80.858%\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from clip import clip\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "model, transform = clip.load(\"RN50x4\", device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
